Paper_ID,Bucket,Title,Authors,Year,Directness,Evidence_Quality,Transferability,Recency,Bucket_Relevance,Implementation_Value,Priority_Score,Tier,Primary_Link,Key_Finding,Reading_Status,Notes
1,A,Measuring Faithfulness in Chain-of-Thought Reasoning,Lanham et al.,2023,5,5,5,3,5,5,4.65,Tier 1,https://arxiv.org/abs/2307.13702,Foundational faithfulness methodology; Early Answering protocol,Not Started,
2,A,Making Reasoning Matter: Measuring and Improving Faithfulness,Lanham et al. / Paul et al.,2024,5,5,5,4,5,5,4.75,Tier 1,Findings of EMNLP 2024,Updated faithfulness framework; FRODO methodology,Not Started,"Same paper as #4 - different author listings"
3,A,Language Models Don't Always Say What They Think,Turpin et al.,2023,5,5,5,3,5,5,4.65,Tier 1,https://proceedings.neurips.cc/paper_files/paper/2023/file/ed3fea9033a80fea1376299fa7863f4a-Paper-Conference.pdf,36% accuracy drop with biasing; 15% unfaithful explanations have no errors,Not Started,
4,A,Making Reasoning Matter: Measuring and Improving Faithfulness,Paul et al. / Lanham et al.,2024,5,5,5,4,5,5,4.75,Tier 1,Findings of EMNLP 2024,Introduces FRODO framework for faithfulness,Not Started,"Same paper as #2 - different author listings"
5,A,Faithful Chain-of-Thought Reasoning,Lyu et al.,2023,4,5,4,3,4,4,4.2,Tier 2,https://arxiv.org/abs/2301.13379,Faithful CoT architecture (Translation â†’ Solver),Not Started,
6,A,On Measuring Faithfulness or Self-Consistency,Paul & West,2024,4,4,4,4,4,4,4.0,Tier 2,ACL 2024,Self-consistency metrics for faithfulness,Not Started,
7,A,A Causal Lens for Evaluating Faithfulness Metrics,Ibrahim et al.,2025,4,4,4,5,4,4,4.2,Tier 2,https://arxiv.org/abs/2502.18848,Causal evaluation framework,Not Started,
8,A,TokenSHAP: Interpreting Large Language Models,Tsai et al.,2024,3,4,3,4,3,4,3.5,Tier 3,https://arxiv.org/abs/2407.10114,SHAP-based interpretation method,Not Started,
9,A,Faithful Group Shapley Value,Lundberg et al.,2024,3,4,3,4,3,4,3.5,Tier 3,https://openreview.net,Group Shapley for faithfulness,Not Started,
10,A,Benchmarking Instance-Level Faithfulness,FaithCoT-Bench,2025,4,4,4,5,4,4,4.2,Tier 2,https://arxiv.org/html/2510.04040v1,Faithfulness benchmarking dataset,Not Started,
11,A,The Probabilities Also Matter,ResearchGate,2024,3,3,3,4,3,3,3.1,Tier 3,https://www.researchgate.net/publication/384212923,Probability-based faithfulness metric,Not Started,
12,B,Simple Synthetic Data Reduces Sycophancy in Large Language Models,Wei et al.,2023,5,5,5,3,5,5,4.65,Tier 1,https://arxiv.org/abs/2308.03958,RLHF increases sycophancy 18% to 75%; mitigation strategies,Not Started,
13,B,Towards Understanding Sycophancy in Language Models,Anthropic,2024,5,4,5,4,5,5,4.7,Tier 1,https://arxiv.org/abs/2310.13548,Comprehensive sycophancy analysis,Not Started,
14,B,SycEval: Evaluating LLM Sycophancy,Fanous et al.,2025,5,5,5,5,5,5,5.0,Tier 1,https://arxiv.org/abs/2502.08177,Progressive 43.52%; Regressive 14.66%; clinical context,Not Started,
15,B,Echoes of Agreement: Argument-Driven Sycophancy,Kaur,2025,5,4,5,5,5,5,4.85,Tier 1,Findings of EMNLP 2025,Pylons of Agreement sequence; argument-driven,Not Started,
16,B,Beacon: Single-Turn Diagnosis and Mitigation of Latent Sycophancy,Pandey et al.,2025,5,5,5,5,5,5,5.0,Tier 1,https://arxiv.org/abs/2510.16727,Latent sycophancy via token probabilities,Not Started,
17,B,ELEPHANT and SYCON-Bench: Measuring Social Sycophancy,Hong et al.,2025,5,4,5,5,5,5,4.85,Tier 1,Findings of EMNLP 2025,Third-person framing reduces sycophancy 60%+,Not Started,
18,B,Truth Decay: Quantifying Multi-Turn Sycophancy,Liu et al.,2025,5,5,5,5,5,5,5.0,Tier 1,https://arxiv.org/abs/2503.11656,Multi-turn sycophancy quantification,Not Started,
19,B,Alignment Faking in Large Language Models,Anthropic,2024,4,4,4,4,4,4,4.0,Tier 2,Anthropic Whitepaper,Strategic deception in LLMs,Not Started,
20,B,Empirical Evidence for Alignment Faking in a Small LLM,Koorndijk,2025,4,4,4,5,4,4,4.2,Tier 2,https://arxiv.org/abs/2506.21584,Alignment faking in smaller models,Not Started,
21,B,Frontier Models are Capable of In-Context Scheming,Meinke et al.,2024,4,3,4,4,4,4,3.9,Tier 2,Apollo Research Technical Report,Scheming behavior in frontier models,Not Started,
22,B,AI Sandbagging: Language Models Can Strategically Underperform,Van der Weij et al.,2025,4,4,4,5,4,4,4.2,Tier 2,ICLR 2025,Strategic underperformance,Not Started,
23,B,Enhancing Multiple Dimensions of Trustworthiness via Sparse Activation Control,Zou et al.,2024,4,4,4,4,4,4,4.0,Tier 2,NeurIPS 2024,Representation Engineering for mitigation,Not Started,
24,B,Sycophancy Intervention Repository,Google Research,2024,3,3,4,4,3,5,3.7,Tier 3,https://github.com/google/sycophancy-intervention,Implementation resources,Not Started,
25,B,E18: Simple Synthetic Data Reduces Sycophancy in LLMs,Thenraj,2023,3,2,3,3,3,3,2.9,Tier 3,Medium article,Popular summary article,Not Started,
26,B,Understanding and Mitigating Sycophancy in AI Models,Holter,2025,3,3,3,5,3,3,3.3,Tier 3,Technical report,Comparative analysis,Not Started,
27,B,When Helpfulness Backfires: LLMs and the Risk of False Medical Information,Lee et al.,2025,4,4,5,5,4,4,4.4,Tier 2,Journal of Medical Internet Research,Medical context sycophancy risks,Not Started,
28,B,Pointing to a Llama and Call it a Camel: On the Sycophancy of Multimodal LLMs,Pi et al.,2025,3,3,3,5,3,3,3.3,Tier 3,Manuscript under review,Multimodal sycophancy,Not Started,
29,B,A Large-Scale Dataset for Argument Quality Ranking,Gretz et al.,2020,3,4,3,2,3,3,3.1,Tier 3,AAAI 2020,Argument quality dataset,Not Started,
30,D,LLMs Get Lost In Multi-Turn Conversation,Laban et al.,2025,5,5,5,5,5,5,5.0,Tier 1,https://arxiv.org/pdf/2505.06120,39% degradation; 90% to 65% performance drop,Not Started,
31,D,Large Language Models with Temporal Reasoning for Longitudinal Clinical Summarisation,Kruse et al.,2025,5,5,5,5,5,5,5.0,Tier 1,Findings of EMNLP 2025,Clinical longitudinal reasoning; PDSQI-9,Not Started,
32,D,Why LLMs Fail in Multi-Turn Conversations (And How to Fix It),Zheng et al.,2024,5,4,5,4,5,5,4.7,Tier 1,https://www.prompthub.us/blog/why-llms-fail-in-multi-turn-conversations-and-how-to-fix-it,39% accuracy drop in multi-turn,Not Started,
33,D,Drift No More? Context Equilibria in Multi-Turn LLM Interactions,Yuan et al.,2024,4,4,4,4,4,4,4.0,Tier 2,https://arxiv.org/abs/2510.07777,Context equilibria approach,Not Started,
34,D,Can an LLM Induce a Graph? Investigating Memory Drift,Memory Drift Research Group,2024,3,3,3,4,3,3,3.1,Tier 3,Technical report,Memory drift investigation,Not Started,
35,D,Assessing and Mitigating Medical Knowledge Drift,Medical Knowledge Drift Research Group,2024,3,3,4,4,3,3,3.4,Tier 3,Technical report,Medical knowledge drift,Not Started,
36,D,Context Length Alone Hurts LLM Performance Despite Perfect Retrieval,Context Length Research,2025,4,4,4,5,4,4,4.2,Tier 2,https://arxiv.org/abs/2510.05381,Context length impact,Not Started,
37,D,Understanding Model Drift and Data Drift in LLMs,Orq.ai,2025,3,2,3,5,3,3,3.1,Tier 3,Technical blog,Drift overview guide,Not Started,
38,Clinical,Towards Expert-Level Medical Question Answering with Large Language Models,Singhal et al.,2023,4,5,4,3,4,4,4.2,Tier 2,https://arxiv.org/abs/2305.09617,Med-PaLM 2; expert-level performance,Not Started,
39,Clinical,Evaluation and Mitigation of the Limitations of Large Language Models in Clinical Decision-Making,Hager et al.,2024,5,5,5,4,5,5,4.85,Tier 1,Nature Medicine 2024,Models fail in realistic workflows despite exam scores,Not Started,
40,Clinical,Beyond Empathy: Integrating Diagnostic and Therapeutic Reasoning with Large Language Models,Zhang et al. (PsyLLM),2025,5,5,5,5,5,5,5.0,Tier 1,https://arxiv.org/abs/2505.15715,OpenR1-Psy dataset; our primary data source,Not Started,
41,Clinical,Can AI Relate: Testing Large Language Model Response for Mental Health Support,Gabriel et al.,2024,4,4,5,4,4,4,4.3,Tier 2,Findings of EMNLP 2024,2-13% lower empathy for Black patients; bias evidence,Not Started,
42,Clinical,SafeHear: A Novel Evaluation Benchmark for Medical LLMs,Lee et al.,2024,5,5,5,4,5,5,4.85,Tier 1,https://arxiv.org/abs/2507.23486,92% generic vs 68% clinical safety; domain gap,Not Started,
43,Clinical,CARE-AD: A Multi-Agent Large Language Model Framework for Alzheimer's Disease Prediction,Kim et al.,2025,4,5,4,5,4,4,4.4,Tier 2,npj Digital Medicine 2025,Multi-agent approach; 0.53 accuracy 10 years prior,Not Started,
44,Clinical,DENSE: Longitudinal Progress Note Generation with Temporal Modelling,Chen et al.,2025,4,4,4,5,4,4,4.2,Tier 2,https://arxiv.org/abs/2507.14079,Longitudinal note generation,Not Started,
45,Clinical,A Question Answering Dataset for Medical Question Understanding,Ben Abacha & Demner-Fushman,2019,3,4,3,2,3,3,3.1,Tier 3,ACL 2019,MedQuad dataset,Not Started,
46,Clinical,MedKGEval: A Knowledge Graph-Based Evaluation Framework for Medical LLMs,MedKG Research Group,2025,4,4,4,5,4,4,4.2,Tier 2,Proceedings of the Web Conference 2025,Knowledge graph evaluation,Not Started,
47,Tools,Development and Validation of the Provider Documentation Summarisation Quality Instrument,Kim et al.,2025,5,5,5,5,5,5,5.0,Tier 1,https://arxiv.org/abs/2501.08977,PDSQI-9 instrument; used in Study C,Not Started,
48,Tools,Automating Evaluation of AI Text Generation in Healthcare with an LLM-as-a-Judge,Smith et al.,2025,4,4,4,5,4,4,4.2,Tier 2,https://www.medrxiv.org/content/10.1101/2025.04.22.25326219v1,LLM-as-judge methodology,Not Started,
49,Tools,Evaluating Clinical AI Summaries with LLMs-as-Judges,Cheng et al.,2025,4,4,4,5,4,4,4.2,Tier 2,medRxiv preprint,Clinical summary evaluation,Not Started,
50,Tools,Faithfulness Metric Documentation,Ragas,2025,3,3,4,5,3,4,3.6,Tier 3,https://docs.ragas.io/en/stable/concepts/metrics/available_metrics/faithfulness,Documentation reference,Not Started,
51,Tools,Dialogue Natural Language Inference,Welleck et al.,2019,4,4,4,2,4,4,3.8,Tier 2,ACL 2019,Dialogue NLI for conflict detection,Not Started,
52,Methods,Self-Refine: Iterative Refinement with Feedback from Large Language Models,Madaan et al.,2023,3,4,3,3,3,3,3.3,Tier 3,https://arxiv.org/abs/2303.17651,Self-refinement methodology,Not Started,
53,Methods,Reflexion: Language Agents with Verbal Reinforcement Learning,Shinn et al.,2023,3,4,3,3,3,3,3.3,Tier 3,https://arxiv.org/abs/2303.11366,Reflexion methodology,Not Started,
54,Survey,LLLMs: A Data-Driven Survey of Evolving Research on Limitations of Large Language Models,Zhao et al.,2025,4,4,4,5,4,4,4.2,Tier 2,ResearchGate,Comprehensive survey,Not Started,
55,Survey,Measuring and Improving the Faithfulness of Model-Generated Reasoning,LessWrong,2023,3,2,3,3,3,3,2.9,Tier 3,LessWrong technical note,Technical note,Not Started,
56,Resource,BIG-Bench Hard: Individual task performance data,BIG-Bench Hard,2023,3,3,3,3,3,3,3.0,Tier 3,https://www.researchgate.net/figure/BIG-Bench-Hard-1827-individual-task-performance_tbl3_372989811,Benchmark data,Not Started,
57,Resource,Jerry Wei's Research Contributions,Jerry Wei,2023,3,3,3,3,3,3,3.0,Tier 3,https://www.researchgate.net/scientific-contributions/Jerry-Wei-2152948001,Researcher profile,Not Started,
58,Resource,10 LLM Safety and Bias Benchmarks,Evidently AI,2024,3,2,3,4,3,3,3.0,Tier 3,https://www.evidentlyai.com/blog/llm-safety-bias-benchmarks,Blog article,Not Started,
59,Resource,Risk Management for Mitigating Benchmark Failure Modes,BenchRisk,2024,3,3,3,4,3,3,3.1,Tier 3,https://openreview.net/pdf?id=YAGa8upUSA,Benchmark risk management,Not Started,
60,Resource,Hugging Face Papers: Mental Health Counseling,Hugging Face,2024,2,2,2,4,2,2,2.2,Tier 3,https://huggingface.co/papers?q=mental%20health%20counseling,Paper search,Not Started,

